{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Network, Na√Øve Bayes and TAN Bayes Classifiers\n",
    "\n",
    "## UNSW Sydney, September 2022\n",
    "\n",
    "- Student name 1 - zID1\n",
    "- Student name 2 - zID2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "**Submission deadline:** Sunday, 16th October 2022, at 18:00:00 AEDT.\n",
    "\n",
    "**Late Submission Policy:** The penalty is set at $5\\%$ per late day for a maximum of 5 days. This is the UNSW standard late penalty. For example, if an assignment receives an on-time mark of 70/100 and is submitted three days late, it will receive a mark reduction of $70/100*15\\%$. After five days, the assignment will receive a mark reduction of $100\\%$.\n",
    "\n",
    "**Form of Submission:** This is an **individual** or group of **two students** assignment. Write the name(s) and zID(s) in this Jupyter notebook. **If submitted in a group, only one member should submit the assignment. Also, create a group on WebCMS by clicking on Groups and Create and include both group members**.\n",
    "\n",
    "You can reuse any piece of source code developed in the tutorials.\n",
    "\n",
    "You can submit your solution via [WebCMS](https://webcms3.cse.unsw.edu.au/COMP9418/22T3).\n",
    "\n",
    "Alternatively, you can submit your solution using give. On a CSE Linux machine, type the following on the command line:\n",
    "\n",
    "``$ give cs9418 ass1 solution.zip``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries you are allowed to use. No other libraries will be accepted. Make sure you are using Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the python files we developed in tutorials or any other code from the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DiscreteFactors import Factor\n",
    "from Graph import Graph\n",
    "from BayesNet import BayesNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Graph({\n",
    "    \"LymphNodes\": [],\n",
    "    'Metastasis': [\"LymphNodes\"],\n",
    "    \"BC\": [\"Metastasis\",\"Mass\",\"AD\",\"NippleDischarge\",\"SkinRetract\",\"MC\"],\n",
    "    \"Age\": [\"BC\"],\n",
    "    \"Location\": [\"BC\"],\n",
    "    \"MC\": [],\n",
    "    \"SkinRetract\": [],\n",
    "    \"NippleDischarge\": [],\n",
    "    \"AD\": [\"FibrTissueDev\"],\n",
    "    \"FibrTissueDev\": [\"NippleDischarge\",\"SkinRetract\",\"Spiculation\"],\n",
    "    \"Spiculation\": [\"Margin\"],\n",
    "    \"Margin\": [],\n",
    "    \"Mass\": [\"Margin\",\"Shape\",\"Size\"],\n",
    "    \"Shape\": [],\n",
    "    \"Size\": [],\n",
    "    \"BreastDensity\": [\"Mass\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "# remove 2 variables from data (because we are pretending we don't know this information)\n",
    "if 'Metastasis' in data:\n",
    "    del data['Metastasis']\n",
    "if 'LymphNodes' in data:\n",
    "    del data['LymphNodes']\n",
    "\n",
    "# remove same 2 nodes from graph\n",
    "G.remove_node('Metastasis')\n",
    "G.remove_node('LymphNodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``d_separation(G, X, Z, Y)`` that return a boolean: ``True`` if **X** is d-separated from **Y** given **Z** in the graph $G$ and ``False`` otherwise.\n",
    "\n",
    "* **X**,**Y** and **Z** are python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers and can be assumed to be nodes of the graph $G$. \n",
    "* $G$ is a directed graph object as defined in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for d_separation(G, X, Z, Y) in this cell\n",
    "\n",
    "def find_path_r(start, end, G):\n",
    "    if start == end:\n",
    "        return True\n",
    "    \n",
    "    G.colour[start] = 'grey'\n",
    "    \n",
    "    found = False\n",
    "    for w in G.adj_list[start]: \n",
    "        if G.colour[w] == 'white':\n",
    "            found = find_path_r(w, end, G)\n",
    "            \n",
    "        if found == True:\n",
    "            break \n",
    "            \n",
    "    return found\n",
    "\n",
    "\n",
    "def find_path(start, end, G):\n",
    "    G = copy.deepcopy(G)\n",
    "    G.colour = {node: 'white' for node in G.adj_list.keys()}\n",
    "    return find_path_r(start, end, G)\n",
    "\n",
    "\n",
    "def d_separation(G, X, Z, Y):\n",
    "    '''\n",
    "    Arguments:\n",
    "        G:   is an object of type Graph (the class you developed in tutorial 1).\n",
    "        X,Z and Y:  are python set objects.\n",
    "    Returns:\n",
    "        True if X is d-separared of Y given Z or False otherwise.\n",
    "    '''\n",
    "\n",
    "    G1 = G.copy()\n",
    "    \n",
    "    for node in G:\n",
    "        if len(G.adj_list[node]) == 0:            \n",
    "            if (node not in X) and (node not in Z) and (node not in Y):\n",
    "                G1.remove_node(node)\n",
    "\n",
    "    for node in Z:\n",
    "        G1.adj_list[node] = []\n",
    "    \n",
    "    for start in G1:\n",
    "        for end in G1:\n",
    "            if start == end:\n",
    "                continue\n",
    "            \n",
    "            if (start in G1.adj_list[end]) and (end not in G1.adj_list[start]):\n",
    "                G1.adj_list[start].append(end)\n",
    "    \n",
    "    for start in X:\n",
    "        for end in Y:\n",
    "            has_path = find_path(start, end, G1)\n",
    "            \n",
    "            if has_path == True:\n",
    "                return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "        \n",
    "test(d_separation(G, set(['Age']), set(['BC']), set(['AD'])))\n",
    "test(not d_separation(G, set(['Spiculation', 'SkinRetract']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 2 - Markov blanket\n",
    "\n",
    "The Markov blanket for a variable $X$ is a set of variables that, when observed, will render every other variable irrelevant to $X$. If the distribution is induced by DAG $G$, then a Markov blanket for variable $X$ can be constructed using $X$'s parents, children, and spouses in $G$. A variable $Y$ is a spouse of $X$ if the two variables have a common child in $G$.\n",
    "\n",
    "In this exercise, we will implement a function `Markov(G, X)` that returns a python set with the Markov blanket of $X$ in $G$ as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for Markov_blanket(G, X) in this cell\n",
    "\n",
    "def find_patrents(G, child):\n",
    "    graphT = G.transpose()\n",
    "    return graphT.adj_list[child]\n",
    "    \n",
    "\n",
    "def Markov_blanket(G, X):\n",
    "    '''\n",
    "    Arguments:\n",
    "        G:   is an object of type Graph (the class you developed in tutorial 1)\n",
    "        X:   is a node (variable) in G.\n",
    "    Returns: \n",
    "        A python set with the Markov blanked of X in G\n",
    "    '''\n",
    "    G = G.copy()\n",
    "    \n",
    "    parents = find_patrents(G, X)\n",
    "    children = G.adj_list[X]\n",
    "    \n",
    "    siblings = []\n",
    "    for child in G.adj_list[X]:\n",
    "        siblings = siblings + find_patrents(G, child)\n",
    "    \n",
    "    blanket = parents + children + siblings\n",
    "    \n",
    "    Mb = []\n",
    "    for node in blanket:\n",
    "        if node != X:\n",
    "            Mb.append(node)\n",
    "    \n",
    "    Mb = set(Mb)\n",
    "    \n",
    "    return Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "test(Markov_blanket(G, 'Mass') == set(['Margin', 'Size', 'Shape', 'BreastDensity', 'BC', 'Spiculation']))\n",
    "test(Markov_blanket(G, 'Age') == set(['Location', 'BC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Tasks 1 and 2 together\n",
    "\n",
    "This task is optional and will not be marked, but you can use it to test your code further. According to the Markov blanket definition: A Markov blanket for a variable $X \\in \\textbf{X}$ is the set of variables $\\textbf{B} \\subseteq \\textbf{X}$ such that $X \\notin \\textbf{B}$ and $X \\perp \\textbf{X} \\setminus (\\textbf{B} \\cup \\{ X \\}) | \\textbf{B}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code to test your d-separation and Markov blanket implementations using the definition above.\n",
    "\n",
    "set_X = {...}                                        # Set of all nodes in the graph\n",
    "for X in set_X:\n",
    "    mb = ...                                         # Markov_blanket of X\n",
    "    ...                                              # Independence test according to the definition above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 3 - Learning the outcome space from data\n",
    "\n",
    "Now, we will implement a series of functions to learn Bayesian network parameters from data. We will start by learning the outcome space of the variables in a Bayesian network. Remind from the tutorials that the outcome space is a python dictionary that maps the variable names to a tuple with the possible values this variable can have.\n",
    "\n",
    "Implement a function ``learn_outcome_space(dataframe)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``dataframe`` and returns a dictionary ``outcomeSpace`` with these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for learn_outcome_space(dataframe) in this cell\n",
    "\n",
    "def learn_outcome_space(dataframe):\n",
    "    '''\n",
    "    Arguments:\n",
    "        dataframe:    A pandas dataframe\n",
    "    Returns: \n",
    "        outcomeSpace: A dictionary. e.g. {'A':('True', 'False'), 'B':('up','down','left'), 'C':(1,2,3,4)}\n",
    "    '''\n",
    "    \n",
    "    outcomeSpace = {}\n",
    "    for column in dataframe.columns.values:\n",
    "            outcome_space = []\n",
    "            for data in dataframe[column]:\n",
    "                if data not in outcome_space:\n",
    "                    outcome_space.append(data)\n",
    "            \n",
    "            outcomeSpace[column] = tuple(outcome_space)\n",
    "    \n",
    "    return outcomeSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "\n",
    "outcomes = outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "test(len(outcomes) == len(answer) and set(outcomes) == set(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 4 - Estimate Bayesian network parameters from data\n",
    "\n",
    "Implement a method ``model.learn_parameters(dataframe, alpha=1)`` that learns the parameters of the Bayesian Network `model`. This function should do the same as the ``learn_parameters`` function from tutorials, but it should also implement laplacian smoothing with parameter $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_parameters(self, dataframe, alpha) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "\n",
    "    def estimateFactor(self, data, var_name, parent_names, outcomeSpace, alpha):\n",
    "        \"\"\"\n",
    "        Calculate a dictionary probability table by ML given\n",
    "        `data`, a dictionary or dataframe of observations\n",
    "        `var_name`, the column of the data to be used for the conditioned variable and\n",
    "        `parent_names`, a tuple of columns to be used for the parents and\n",
    "        `outcomeSpace`, a dict that maps variable names to a tuple of possible outcomes\n",
    "        Return a dictionary containing an estimated conditional probability table.\n",
    "        \"\"\"    \n",
    "        var_outcomes = outcomeSpace[var_name]\n",
    "        parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "        # cartesian product to generate a table of all possible outcomes\n",
    "        all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "        f = Factor(list(parent_names)+[var_name], outcomeSpace)\n",
    "\n",
    "        for i, parent_combination in enumerate(all_parent_combinations):\n",
    "            parent_vars = dict(zip(parent_names, parent_combination))\n",
    "            parent_index = self.allEqualThisIndex(data, **parent_vars)\n",
    "            for var_outcome in var_outcomes:\n",
    "                var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "                f[tuple(list(parent_combination)+[var_outcome])] = \\\n",
    "                ((var_index & parent_index).sum() + alpha) / (parent_index.sum() + len(outcomeSpace[var_name]) * alpha)\n",
    "\n",
    "        return f\n",
    "    \n",
    "    def learn_parameters(self, dataframe, alpha=1):\n",
    "        '''\n",
    "        Arguments:\n",
    "            data:    A pandas dataframe\n",
    "            alpha:   Laplacian smoothing parameter\n",
    "        '''        \n",
    "        graphT = self.graph.transpose()\n",
    "        for node, parents in graphT.adj_list.items():\n",
    "            self.factors[node] = self.estimateFactor(data, node, parents, outcomeSpace, alpha)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "model = BayesNet(G, outcomeSpace=outcomeSpace)\n",
    "\n",
    "model.learn_parameters(data, alpha=1)\n",
    "l = ('No', 'high', 'No')\n",
    "\n",
    "test(model.factors['Age']['35-49'] == 0.248000399920016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 5 - Bayesian network classification\n",
    "\n",
    "Design a new method ``model.predict(class_var, evidence)`` that implements the classification with complete data. This function should return the MPE value for the attribute `class_var` given the evidence. As we are working with complete data, `evidence` is an instantiation for all variables in the Bayesian network `model` but `class_var`.\n",
    "\n",
    "**Implement the efficient classification procedure discussed in the lectures. Assure that you only join the necessary factors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for predict(self, class_var, evidence) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "    def find_all_joint_probability(self, class_var, class_value, evidence):\n",
    "        all_values = copy.deepcopy(evidence)\n",
    "        all_values[class_var] = class_value\n",
    "        \n",
    "        mul = 1\n",
    "        for node in all_values.keys():\n",
    "            fac = self.factors[node]\n",
    "            \n",
    "            l = []\n",
    "            for d in fac.domain:\n",
    "                l.append(all_values[d])\n",
    "            \n",
    "            l = tuple(l)\n",
    "            mul *= self.factors[node][l]\n",
    "        \n",
    "        return mul\n",
    "    \n",
    "    \n",
    "    def get_evidence_probability(self, class_var, evidence):\n",
    "        probability = 0\n",
    "        for class_value in self.outcomeSpace[class_var]:\n",
    "            probability += self.find_all_joint_probability(class_var, class_value, evidence)\n",
    "            \n",
    "        return probability\n",
    "        \n",
    "    \n",
    "    def predict(self, class_var, evidence):\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            The MPE value (class label) of class_var given evidence\n",
    "        '''        \n",
    "        class_probabilities = {}\n",
    "        for class_value in self.outcomeSpace[class_var]:\n",
    "            class_probabilities[class_value] = \\\n",
    "            self.find_all_joint_probability(class_var, class_value, evidence) / self.get_evidence_probability(class_var, evidence)\n",
    "        \n",
    "        return max(class_probabilities, key=lambda x:class_probabilities[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "model = BayesNet(G, outcomeSpace=outcomeSpace)\n",
    "model.learn_parameters(data, alpha=1)\n",
    "\n",
    "evidence = {'Age': '35-49', \n",
    "    'Location': 'LolwOutQuad', \n",
    "    'MC': 'No', \n",
    "    'SkinRetract': 'No', \n",
    "    'NippleDischarge': 'No',\n",
    "    'AD': 'No',\n",
    "    'FibrTissueDev': 'No', \n",
    "    'Spiculation': 'No',\n",
    "    'Margin': 'Well-defined', \n",
    "    'Mass': 'No',\n",
    "    'Shape': 'Other', \n",
    "    'Size': '<1cm',\n",
    "    'BreastDensity': 'high'}\n",
    "\n",
    "test(model.predict('BC', evidence) == 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 6 - Bayesian network accuracy estimation\n",
    "\n",
    "Design a new function ``assess_bayes_net(model, dataframe, class_var)`` that uses the test cases in ``dataframe`` to assess the Bayesian network `model` performance at classifying the variable `class_var`. This function will return the accuracy of the Bayesian network according to the examples in ``dataframe``.\n",
    "\n",
    "Remind that accuracy is the ratio of the number of correct predictions to the total number of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_bayes_net(model, dataframe, class_var) in this cell\n",
    "\n",
    "# model = BayesNet(...)\n",
    "def assess_bayes_net(model, dataframe, class_var):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:     Bayesian Network object\n",
    "        dataframe: a Pandas dataframe object\n",
    "        class_var: Variable identifier to be classified\n",
    "    Returns:\n",
    "        The accuracy of the Bayesian network model in classifying the cases in dataframe\n",
    "    '''     \n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        total_count += 1\n",
    "        \n",
    "        real_bc = row[class_var]\n",
    "        \n",
    "        evidence = {}\n",
    "        for key in row.keys():\n",
    "            if key != class_var:\n",
    "                evidence[key] = row[key]\n",
    "        \n",
    "        prediction = model.predict(class_var, evidence)\n",
    "        \n",
    "        if real_bc == prediction:\n",
    "            correct_count += 1\n",
    "        \n",
    "    return correct_count/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "model = BayesNet(G, outcomeSpace)\n",
    "model.learn_parameters(data, alpha=1)\n",
    "\n",
    "acc = assess_bayes_net(model, data, 'BC')\n",
    "test(abs(acc-0.8423) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 7 - Bayesian network assessment with cross-validation\n",
    "\n",
    "Implement a function called `cross_validation_bayes_net(G, dataframe, class_var, k)`, compute and report the average accuracy of the Bayesian network specified by the graph `G` over a $k=10$ cross-validation runs as well as the standard deviation. A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cross_validation_bayes_net(G, dataframe, class_var, k) in this cell\n",
    "\n",
    "def cross_validation_bayes_net(G, dataframe, class_var, k=10):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      Bayesian Network object\n",
    "        dataframe:  a Pandas dataframe object\n",
    "        class_var:  Variable identifier to be classified\n",
    "        k:          number of cross-validation folds\n",
    "    Returns:\n",
    "        The mean accuracy and standand deviation of model across the k folds\n",
    "    '''      \n",
    "    accuracy_list = []\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = 42)\n",
    "    for train, test in kf.split(dataframe):\n",
    "        train_data = dataframe.iloc[train]\n",
    "        test_data = dataframe.iloc[test]\n",
    "        \n",
    "        # train a model with learn_parameters\n",
    "        outcomeSpace = learn_outcome_space(train_data)\n",
    "        model = BayesNet(G, outcomeSpace)\n",
    "        model.learn_parameters(train_data, alpha=1)\n",
    "        \n",
    "        # test the model with assess_bayes_net\n",
    "        acc = assess_bayes_net(model, test_data, class_var)\n",
    "        \n",
    "        accuracy_list.append(acc)\n",
    "        \n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cross_validation_bayes_net(G, data, 'BC', 10)\n",
    "test(abs(acc - 0.85) < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 8 - Na√Øve Bayes classifier structure\n",
    "\n",
    "Let's work now with the Na√Øve Bayes classifier. This classifier is a Bayesian network with a pre-defined structure (graph). Let's start creating a new function, ``learn_naive_bayes_structure(dataframe, class_var)``, that learns the Na√Øve Bayes graph structure from a pandas `dataframe` using `class_var` as the class variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_naive_bayes_structure(dataframe, class_var) in this cell\n",
    "\n",
    "def learn_naive_bayes_structure(dataframe, class_var):\n",
    "    '''\n",
    "    Arguments:\n",
    "        dataframe:   A pandas dataframe\n",
    "        class_var:   Variable identifier to be classified\n",
    "    Returns:\n",
    "        A Graph object with the structure of the Na√Øve Bayes classifier for the attributes in dataframe\n",
    "    '''\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "naiveG = learn_naive_bayes_structure(data, 'BC')\n",
    "naiveG.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 9 - Na√Øve Bayes classification\n",
    "\n",
    "As the Na√Øve Bayes classifier is a Bayesian network, we can use the existing `BayesNet` class to create a new class `NaiveBayes`.\n",
    "\n",
    "Let's create a new method ``model.predict_log(class_var, evidence)`` that implements the classification with complete data. This function should return the MPE value for the attribute `class_var` given the `evidence`. As we work with complete data, `evidence` is an instantiation for all variables but `class_var`. **Use the log probability trick discussed in the lectures to classify each example**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for predict_log(self, class_var, evidence) in this cell\n",
    "\n",
    "class NaiveBayes(BayesNet):\n",
    "    def predict_log(self, class_var, evidence):\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            The MPE value (class label) of class_var given evidence\n",
    "        '''        \n",
    "        ...\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "naiveG = learn_naive_bayes_structure(data, 'BC')\n",
    "naive_model = NaiveBayes(naiveG, outcomeSpace=outcomeSpace)\n",
    "naive_model.learn_parameters(data, alpha=1)\n",
    "evidence = {'Age': '35-49', \n",
    "    'Location': 'LolwOutQuad', \n",
    "    'MC': 'No', \n",
    "    'SkinRetract': 'No', \n",
    "    'NippleDischarge': 'No',\n",
    "    'AD': 'No',\n",
    "    'FibrTissueDev': 'No', \n",
    "    'Spiculation': 'No',\n",
    "    'Margin': 'Well-defined', \n",
    "    'Mass': 'No',\n",
    "    'Shape': 'Other', \n",
    "    'Size': '<1cm',\n",
    "    'BreastDensity': 'high'}\n",
    "\n",
    "test(naive_model.predict_log('BC', evidence) == 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 10 - Na√Øve Bayes accuracy estimation\n",
    "\n",
    "Design a new function ``assess_naive_bayes(model, dataframe, class_var)`` that uses the test cases in ``dataframe`` to assess the performance of the Na√Øve Bayes classifier for the class variable `class_var`. This function will return the accuracy of the classifier according to the examples in the ``dataframe``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_naive_bayes(model, dataframe, class_var) in this cell\n",
    "\n",
    "model = NaiveBayes(...)\n",
    "def assess_naive_bayes(model, dataframe, class_var='BC'):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      Naive Bayes object\n",
    "        dataframe:  a Pandas dataframe object\n",
    "        class_var:  Variable identifier to be classified\n",
    "    Returns:\n",
    "        The accuracy of the Naive Bayes model in classifying the cases in dataframe\n",
    "    '''      \n",
    "    ...\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "## Note: More hidden tests will be used. You should make more tests yourself.\n",
    "\n",
    "naive_model = NaiveBayes(naiveG, outcomeSpace)\n",
    "naive_model.learn_parameters(data, alpha=1)\n",
    "\n",
    "acc = assess_naive_bayes(naive_model, data, 'BC')\n",
    "test(abs(acc-0.7926) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 11 - Na√Øve Bayes assessment with cross-validation\n",
    "\n",
    "Implement a function called `cross_validation_naive_bayes(dataframe, class_var, k)`, compute and report the average accuracy over the $k=10$-fold cross-validation runs as well as the standard deviation. A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cross_validation_naive_bayes(dataframe, class_var, k) in this cell\n",
    "\n",
    "def cross_validation_naive_bayes(dataframe, class_var='BC', k=10):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = 42)\n",
    "    for train, test in kf.split(dataframe):\n",
    "      \n",
    "        # train a model with learn_parameters\n",
    "        ...\n",
    "        \n",
    "        # test the model with assess_bayes_net\n",
    "        acc = ...\n",
    "        \n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cross_validation_naive_bayes(data, 'BC')\n",
    "test(abs(acc - 0.80) < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [15 Marks] Task 12 - Tree-augmented na√Øve Bayes structure\n",
    "\n",
    "Let's work now with the Tree-augmented Na√Øve Bayes classifier. We will start creating a new function, ``learn_tan_structure(dataframe, class_var)``, that learns the Tree-augmented Bayes graph structure from a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_tan_structure(dataframe, class_var) in this cell\n",
    "\n",
    "def learn_tan_structure(dataframe, class_var):\n",
    "    '''\n",
    "    Arguments:\n",
    "        dataframe - A pandas dataframe\n",
    "        class_var - Variable identifier to be classified\n",
    "    Returns:\n",
    "        A Graph object with the structure of the Na√Øve Bayes classifier for the attributes in dataframe and class_var\n",
    "    '''\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "tan_graph = learn_tan_structure(data, class_var='BC')\n",
    "test(len(tan_graph.children('BC')) == len(tan_graph)-1)\n",
    "test('FibrTissueDev' in tan_graph.children('Spiculation') or 'Spiculation' in tan_graph.children('FibrTissueDev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 13 - Tree-augmented na√Øve Bayes assessment with cross-validation\n",
    "\n",
    "Implement a function called `cross_validation_tan(dataframe, class_var, k)`, compute and report the average accuracy over the $k=10$-fold cross-validation runs and the standard deviation. A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cross_validation_tan(dataframe, class_var, k) in this cell\n",
    "\n",
    "def cross_validation_tan(dataframe, class_var='BC', k=10):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = 42)\n",
    "    for train, test in kf.split(dataframe):\n",
    "      \n",
    "        # train a model with learn_parameters\n",
    "        ...\n",
    "        \n",
    "        # test the model with assess_bayes_net\n",
    "        acc = ...\n",
    "        \n",
    "        accuracy_list.append(acc)\n",
    "    return np.mean(accuracy_list), np.std(accuracy_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cross_validation_tan(data, 'BC')\n",
    "test(abs(acc - 0.83) < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 14 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results. You can analyse your results from different aspects such as accuracy, runtime, coding complexity and independence assumptions. You can use plots to illustrate your results.\n",
    "\n",
    "b. Discuss the time and memory complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter notebook. Develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please, be concise and objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Write your report in one or more cells here.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
